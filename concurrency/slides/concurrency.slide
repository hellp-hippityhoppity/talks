Concurrency at Turnitin
26 Jan 2016
Tags: go meetup, concurrency, semaphore, worker pools, go northeast, golang northeast, graceful shutdown

Nathan Davies
Software Engineer, Turnitin
ndavies@turnitin.com
github.com/nathj07
@nathj07

* Scene Setting
- Not a theoretical walkthrough; see the resources slide
- How we use concurrency at Turnitin
- real world examples
- cautionary tales

* Rate limiting
- the export app; a cautionary tale
- go routines are easy to use
- go routines are pretty lightweight
- go routines can consume resources beyond your own system; size worker pools with that in mind

* Worker Pools
	// md is a slice of data to process
	for i := 0; i < len(md); i++ {
		m := md[i]

		wg.Add(1)
		go func() {
			defer wg.Done()
			...
		}()
	}
	wg.Wait()
- the rate is controlled by the for loop
- unsuitable limits
-  `len(md)`  is unknown ahead of time

* Worker Pools cont'd
- need to have a controlled, deterministic number of workers
	// md is a slice of data to process
	workerCount := 20 // better from config
	for i := 0; i < workerCount; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for record := range mds {
				// do the work
			}
		}()
	}
	wg.Wait()
- impact on external resource is now known and managed
- WaitGroup allows us to ensure certain tasks are complete

* Channels: Buffered v Unbuffered
.play ../code/basic/concurrency.go /^func main/,/^}/
- unbuffered you need something to recevie off before send on _demo_
- buffered seems tempting; leads to the question "How big"

* Batch Flow v Continuous Flow
- continues the discussion on buffered v unbuffered
- processing data can process batches or a continuous flow
- batch means pulling data; processing it all; and repeat - buffered channel
- continuous means pulling data all the time - unbuffered channel

* Batch Flow example
.code ../code/batch/flow.go  /^func main/,/^}/
- very deterministic
- resource use fluctuates
- _demo_and_code_

* Continuous Flow Example
.code ../code/continuous/flow.go  /^func main/,/^}/
- At Tii we switched from batch to continuous flow
- smoother resource use
- better processing rates, not so much blocking
- tasks are more interleaved
- _demo_and_code_

* The Story So Far
- A lot of concurrency primitives used
- `WaitGroup` to control flow
- Parrallelised different actions -  `go routine`
- Run the same task mulitple times on different data - worker pool
- Used `chan` to share memory by communicating

* Up Next
- `select`
- done signals and graceful shutdown

* Example
// TODO: For done use the exmaple https://blog.golang.org/pipelines within the continuous flow code - copy it and add the signal

* Resources
- https://blog.golang.org/share-memory-by-communicating
- https://www.youtube.com/watch?v=cN_DpYBzKso - Rob Pike
- https://gobyexample.com/goroutines - great launch point
- http://spinroot.com/courses/summer/Papers/hoare_1978.pdf - if you really want the nuts and bolts
- https://blog.golang.org/pipelines - pipelines are a great pattern; read and play
- http://jmoiron.net/blog/limiting-concurrency-in-go/
