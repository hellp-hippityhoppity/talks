Concurrency at Turnitin
26 Jan 2016
Tags: go meetup, concurrency, semaphore, worker pools, go northeast, golang northeast, graceful shutdown

Nathan Davies
Software Engineer, Turnitin
ndavies@turnitin.com
@nathj07

* Scene Setting
- Not a theoretical walkthrough; see the resources slide
- How we use concurrency at Turnitin; focussed on one major application
- real world examples
- cautionary tales

* Rate limiting
- go routines are easy to use
- go routines are pretty lightweight
- go routines can consume resources beyond your own system; size worker pools with that in mind

* Worker Pools
	// md is a slice of data to process
	for i := 0; i < len(md); i++ {
		m := md[i]

		wg.Add(1)
		go func() {
			defer wg.Done()
			...
		}()
	}
	wg.Wait()
- unsuitable limits
- the rate is controlled by the for loop
-  `len(md)`  is unknown ahead of time
- a cautionary tale

* Worker Pools cont'd
- need to have a controlled, deterministic number of workers
	// md is a slice of data to process
	workerCount := 20 // better from config
	for i := 0; i < workerCount; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for record := range mds {
				// do the work
			}
		}()
	}
	wg.Wait()
- impact on external resource is now known and managed
- WaitGroup allows us to ensure certain tasks are complete

* Channels: Buffered v Unbuffered
.play ../code/basic/concurrency.go /^func main/,/^}/
- unbuffered you need something to recevie off before send on _demo_
- buffered seems tempting; leads to the question "How big"

* Batch Flow v Continuous Flow
- processing data can process batches or a continuous flow
- batch means pulling data; processing it all; pulling more - buffered channel
- continuous means pulling data all the time - unbuffered channel

* Batch Flow example
.code ../code/batch/flow.go  /^func main/,/^}/
- _to_the_terminal_
- very deterministic
- memory will saw-tooth; especially if do more than print!
- _to_the_code_

* Continuous Flow Example
.code ../code/continuous/flow.go  /^func main/,/^}/
- _to_the_terminal_
- At Tii we switched from batch to continuous flow
- smoother resource use
- better processing rates, not so much blocking
- _to_the_code_

* The Story So Far
- `WaitGroup` to control flow
- Parrallelised different actions -  multiple `go routine`
- Run the same task mulitple times on different data - worker pool
- Used `chan` to share memory by communicating
- A lot of concurrency primitives used

* Up Next
- `select`
- done signals and graceful shutdown

* Example
// TODO: For done use the exmaple https://blog.golang.org/pipelines within the continuous flow code - copy it and add the signal

* Resources
- https://blog.golang.org/share-memory-by-communicating
- https://www.youtube.com/watch?v=cN_DpYBzKso - Rob Pike
- https://gobyexample.com/goroutines - great launch point
- http://spinroot.com/courses/summer/Papers/hoare_1978.pdf - if you really want the nuts and bolts
- https://blog.golang.org/pipelines - pipelines are a great pattern; read and play
