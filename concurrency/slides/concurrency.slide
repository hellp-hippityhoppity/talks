Concurrency at Turnitin
26 Jan 2016
Tags: go meetup, concurrency, semaphore, worker pools, go northeast, golang northeast, graceful shutdown

Nathan Davies
Snr Software Engineer, Turnitin
ndavies@turnitin.com
http://github.com/nathj07
@nathj07

* Scene Setting
- Not a theoretical walk through; see the resources slide
- How we use concurrency at Turnitin
- Real world examples

* Primitives
- go routines
- channels
: We will be covering the go routine and channel primitives, showing how they have been used at Turnitin.
: This talk does not cover the race detector, perhaps a separate talk on data races, and we do not look at mutexes.
: Mutexes are ignored in this talk as they are rarely used and I wanted to maintain focus on go routines and channels
: If you want to talk more about mutexes let's do it in the pub afterwards.


* Worker Pools
- need to have a controlled, deterministic number of workers
	// mds is a channel of data to process
	workerCount := 20 // better from config
	var wg sync.WaitGroup
	for i := 0; i < workerCount; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for record := range mds {
				// do the work
			}
		}()
	}
	wg.Wait()
: impact on external resource is known and managed
: WaitGroup allows us to ensure certain tasks are complete
: Typically we create a channel up front and pass it into the functions that need to send or receive on that channel.


* Channels: Buffered v Unbuffered
.play ../code/basic/concurrency.go /^func main/,/^}/
: buffered seems tempting; leads to the question "How big"
: unbuffered you need something to receive off before send on

* Batch Flow v Continuous Flow
- continues the discussion on buffered v unbuffered
- processing data can process batches or a continuous flow
- batch means pulling data; processing it all; and repeat - buffered channel
- continuous means pulling data all the time - unbuffered channel

* Batch Flow example
.code ../code/batch/flow.go  /^func main/,/^}/
- very deterministic
- resource use grows a lot initially, fluctuates around the peak, then drops

* Continuous Flow Example
.code ../code/continuous/flow.go  /^func main/,/^}/
- smoother resource use
- better processing rates, not so much blocking
- tasks are more interleaved
- _code_and_demo_
: let's jump over to some actual code, running it will help us see more clearly what is happening
: start with batch, we can see the difference here in introducing a worker pool too.
: Without the worker pool we get everything written and then we start processing, even though there is a go routine involved.
: When we add the worker pool we see a different processing order.
: It's less deterministic but we are now moving more continually through the pipeline.
: When we look at the continuous processing model, we see a slight variation in the processing order.
: Essentially the data is moving through the pipeline quicker, each provider is moving to the next step sooner.

* Which to use
- At Tii we use a mixture of continuous and batch, even within a single app
- Continuous flow for those tasks best served by having data move through a pipeline
- Batch where the task can take time
: Essentially our main work flow of a data processing application is done using continuous flow.
: This means we are always pushing data through the pipeline.
: There are a couple of tasks in the pipeline that take a long time to complete, calls out to external services, for example.
: For these we use the buffered channel, allowing us to send the data off to the job and then move on, we don't need to wait
: for the job to complete.
: This combination is very useful and allows us to keep the overall process flowing smoothly. Finding the balance is key.
: If you think you need to add go routines, or tune them, or switch from buffered to unbuffered or vice-versa I'd recommend
: instrumenting your app first. Uses statsd or similar to see how long you wait for a channel, or how long certain actions take.
: Utilise profiling, we've had some great talks on that recently.
: Understand your app and your bottlenecks before adding complexity.


* Return Channel
- channels can be returned from functions
- allows the caller to decide if the call is asynch or not
    func doStuff() chan struct{} {
        c := make(chan struct{})
        go func(){
            defer close(c)
            // all the work is done here
        }()
        return c
    }

* Return Channel contd...
- doStuff can be used synchronously
    doStuff()
    doThings() // there is no wait

- doStuff can be used asynchronously
    c := doStuff()
    <-c // this will block
    doThings()

* Semaphore
- Using channels without go routines
- A buffered channel can act as a semaphore
    sem := make(chan struct{}, 10)
    sem <- struct{}{}
    // take action
    <-sem
: Using a channel like this is simple, and clear.
: We get the control we need around certain actions without complex locking code and it is relatively simple to test
: The empty struct is sued as this effectively compiles down to 0, meaning no memory overhead here.


* Done Signal Example
.code ../code/stopping/stopping.go  /^func main/,/^}/
.code ../code/stopping/stopping.go  /^func stop/,/^}/
- good for continuous flow
- good for managing shutdown

* select and SIGINT
.code ../code/sigint/sigint.go  /NOTIFY/,/NOTIFY//
.code ../code/sigint/sigint.go  /FETCH/,/FETCH//
- graceful shutdown on interrupt
- good for long running apps

* select and sleeping
- sometimes we need a controlled sleep in an app
- deleting old files; we only want to walk the directory once every 12 hours
	func ClearOldItems() {
		for {
			// use filepath.Walk to traverse directory and clear old files off disk

			select {
			case <-m.quit:
				logrus.Info("ClearOldItems, quit signal encountered")
				return
			case <-time.After(12 * time.Hour):
			}
		}
	}
- call this in a go routine

* Resources
- Use the race detector!
- https://blog.golang.org/share-memory-by-communicating - good first read
- https://gobyexample.com/goroutines - great launch point
- https://www.youtube.com/watch?v=cN_DpYBzKso - Rob Pike: concurrency is not parrallelism
- https://blog.golang.org/pipelines - pipelines are a great pattern; read and play
- http://jmoiron.net/blog/limiting-concurrency-in-go/
- http://spinroot.com/courses/summer/Papers/hoare_1978.pdf - if you really want the nuts and bolts
- http://www.thedotpost.com/2015/11/matt-aimonetti-applied-concurrency-in-go - applied concurrency
